{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "ZrGEK-LN7SDt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Preprocessing training data\n",
        "\n",
        "This is the continuation of my previous article. In this article, I will apply a preprocessing method on the dataset that was presented in the previous article (*Keras1.ipynb*), followed by the training of the deep learning networks. At the end, testing results will be presented.\n",
        "\n",
        "It should be noted that the dataset that was presented in the previous article had uneven distribution of true and false cases. In particular, the dataset had 268 true cases and 500 false cases of diabetese. Details on the dataset can be found in the following link: \n",
        "https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.names\n",
        "\n",
        "The deep learning model trained using such dataset can lead to the biasness in the trained network outcome because more true cases are fed to the network than false cases. Such issues has been discussed in the following article by Satya Mallick:\n",
        "\n",
        "https://www.learnopencv.com/bias-variance-tradeoff-in-machine-learning/\n",
        "\n",
        "To avoid it, the dataset should have equal numbers of true and false cases, respectively. Therefore let us create new data that has the property. Furthermore, the training and testing of the model should be done in different sets. Therefore, the data set will be divided into 4 such sets, and one set will be used to train, whereas the remainings are used for testing the model.\n",
        "\n",
        "The preprocessing steps can be explained by the following figure\n",
        "![alt text](preprocessingProcess.png)"
      ]
    },
    {
      "metadata": {
        "id": "HQS7QN8F47lg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install --upgrade -q gspread\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "\n",
        "worksheet = gc.open('pima-indians-diabetes').sheet1\n",
        "\n",
        "# get_all_values gives a list of rows.\n",
        "rows = worksheet.get_all_values()\n",
        "\n",
        "\n",
        "\n",
        "# Convert to a DataFrame and render.\n",
        "import pandas as pd\n",
        "import numpy  as np\n",
        "dataset =pd.DataFrame.from_records(rows)\n",
        "\n",
        "#Converting to numpy arrays for X and Y\n",
        "WholeData=dataset.values[:,:] \n",
        "true_case =np.empty([1,9])\n",
        "false_case =np.empty([1,9])\n",
        "\n",
        "#creating two dataset for true and false case\n",
        "for row in WholeData:\n",
        "   if(row[8]=='1'):\n",
        "    true_case= np.vstack((true_case,row))\n",
        "   else:\n",
        "    false_case= np.vstack((false_case,row))\n",
        "    \n",
        "#deleting the first row as it contains garbage due to empty\n",
        "false_case = false_case[1:-1,:] \n",
        "true_case =true_case[1:-1,:]\n",
        "\n",
        "#creating 4 different sets from true_case and false case\n",
        "dataSet =[]\n",
        "for i in range(4):\n",
        "  temp_set = np.empty([1,9])\n",
        "  for j in range(66):\n",
        "    temp_set = np.vstack((temp_set,true_case[i*67+j,:]))\n",
        "    temp_set = np.vstack((temp_set,false_case[i*67+j,:]))\n",
        "  temp_set = temp_set[1:-1,:]\n",
        "  dataSet.append(temp_set)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oXKh4b8tVks9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now let us initialize 2 neural networks as in the previous case. "
      ]
    },
    {
      "metadata": {
        "id": "w-NLPMqvWP12",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "#Initializing Keras model 1\n",
        "model1 = Sequential()\n",
        "model1.add(Dense(12, input_dim=8, activation='relu',kernel_initializer='random_uniform'))\n",
        "model1.add(Dense(8, activation='relu',kernel_initializer='random_uniform'))\n",
        "model1.add(Dense(1, activation='sigmoid',kernel_initializer='random_uniform'))\n",
        "\n",
        "# Compile model\n",
        "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model1.save_weights('model1.h5')\n",
        "\n",
        "#Initializing Keras model 2\n",
        "model2 = Sequential()\n",
        "model2.add(Dense(8, input_dim=8, activation='relu',kernel_initializer='random_uniform'))\n",
        "model2.add(Dense(12, activation='relu',kernel_initializer='random_uniform'))\n",
        "model2.add(Dense(1, activation='sigmoid',kernel_initializer='random_uniform'))\n",
        "\n",
        "# Compile model\n",
        "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model2.save_weights('model2.h5')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rPbF0DtqXakR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now let us train and test the models"
      ]
    },
    {
      "metadata": {
        "id": "t_I4isiJXeWp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 756
        },
        "outputId": "f98fb0f1-d807-4ab4-bb9e-684fb7bde79a"
      },
      "cell_type": "code",
      "source": [
        "model1Acc = np.zeros([4,4])\n",
        "model2Acc = np.zeros([4,4])\n",
        "\n",
        "for i in range(4):\n",
        "  for j in range(4):\n",
        "    X = dataSet[j][:,0:8]\n",
        "    Y = dataSet[j][:,8]\n",
        "    if(i==j): #train the model\n",
        "      model1.load_weights('model1.h5')\n",
        "      model2.load_weights('model2.h5')\n",
        "      #train the models\n",
        "      print('fitt')\n",
        "      model1.fit(X,Y, epochs=200, batch_size=10,verbose=0)\n",
        "      model2.fit(X,Y, epochs=200, batch_size=10,verbose=0)\n",
        "    \n",
        "      \n",
        "    tempScore = model1.evaluate(X,Y)\n",
        "    model1Acc[i,j]=tempScore[1]\n",
        "    tempScore = model2.evaluate(X,Y)\n",
        "    model2Acc[i,j]=tempScore[1]\n",
        "print(model1Acc)\n",
        "print(model2Acc)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fitt\n",
            "131/131 [==============================] - 0s 84us/step\n",
            "131/131 [==============================] - 0s 93us/step\n",
            "131/131 [==============================] - 0s 60us/step\n",
            "131/131 [==============================] - 0s 57us/step\n",
            "131/131 [==============================] - 0s 80us/step\n",
            "131/131 [==============================] - 0s 67us/step\n",
            "131/131 [==============================] - 0s 67us/step\n",
            "131/131 [==============================] - 0s 66us/step\n",
            "131/131 [==============================] - 0s 67us/step\n",
            "131/131 [==============================] - 0s 61us/step\n",
            "fitt\n",
            "131/131 [==============================] - 0s 40us/step\n",
            "131/131 [==============================] - 0s 72us/step\n",
            "131/131 [==============================] - 0s 90us/step\n",
            "131/131 [==============================] - 0s 100us/step\n",
            "131/131 [==============================] - 0s 52us/step\n",
            "131/131 [==============================] - 0s 101us/step\n",
            "131/131 [==============================] - 0s 85us/step\n",
            "131/131 [==============================] - 0s 70us/step\n",
            "131/131 [==============================] - 0s 61us/step\n",
            "131/131 [==============================] - 0s 76us/step\n",
            "fitt\n",
            "131/131 [==============================] - 0s 38us/step\n",
            "131/131 [==============================] - 0s 76us/step\n",
            "131/131 [==============================] - 0s 53us/step\n",
            "131/131 [==============================] - 0s 68us/step\n",
            "131/131 [==============================] - 0s 53us/step\n",
            "131/131 [==============================] - 0s 79us/step\n",
            "131/131 [==============================] - 0s 78us/step\n",
            "131/131 [==============================] - 0s 78us/step\n",
            "131/131 [==============================] - 0s 80us/step\n",
            "131/131 [==============================] - 0s 61us/step\n",
            "fitt\n",
            "131/131 [==============================] - 0s 40us/step\n",
            "131/131 [==============================] - 0s 87us/step\n",
            "[[0.70992366 0.66412214 0.64122137 0.70992366]\n",
            " [0.70992366 0.75572519 0.6259542  0.65648855]\n",
            " [0.61068702 0.75572519 0.69465649 0.66412214]\n",
            " [0.61068702 0.70229008 0.69465649 0.78625954]]\n",
            "[[0.78625954 0.67938931 0.64885496 0.75572519]\n",
            " [0.78625954 0.80916031 0.64122137 0.66412214]\n",
            " [0.66412214 0.80916031 0.74045802 0.67938931]\n",
            " [0.61068702 0.67938931 0.74045802 0.78625954]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}